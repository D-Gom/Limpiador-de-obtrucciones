{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecciona el rectangulo para realizar la comparacion en la estabilizacion del video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando aparece la imagen, hacer click y arrastrar para seleccionar el rectangulo, luego apretar la letra \"c\" para guardar la imagen, luego escape para continuar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "fileName='uns.mp4'\n",
    "cap = cv2.VideoCapture(fileName)\n",
    "\n",
    "ret, old_frame = cap.read()\n",
    "\n",
    "skipframe=5\n",
    "\n",
    "for i in range (0,skipframe):\n",
    "    ret, old_frame = cap.read()\n",
    "    \n",
    "\n",
    "cv2.imwrite(\"old_frame.jpg\", old_frame)\n",
    "cap.release()   \n",
    "\n",
    "%run click_and_crop.py --image old_frame.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estabiliza el video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Importar video\n",
    "\n",
    "fileName='uns.mp4'\n",
    "cap = cv2.VideoCapture(fileName)\n",
    "\n",
    "ret, old_frame = cap.read()\n",
    "\n",
    "#########################################################\n",
    "skipframe=5\n",
    "\n",
    "for i in range (0,skipframe):\n",
    "    ret, old_frame = cap.read()\n",
    "###########################################################\n",
    "\n",
    "\n",
    "\n",
    "height , width , layers =  old_frame.shape\n",
    "\n",
    "salida = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'XVID'), 30,(width,height))\n",
    "############################################################################################################################\n",
    "#Click to take template\n",
    "\n",
    "template = cv2.imread('template.jpg')\n",
    "#############################################################################################################################\n",
    "\n",
    "\n",
    "#primera deteccion de rectangulo\n",
    "#img = cv2.cvtColor(old_frame,cv2.COLOR_BGR2GRAY)\n",
    "img = old_frame\n",
    "w, h ,l = template.shape[::-1]\n",
    "\n",
    "# Apply template Matching\n",
    "res = cv2.matchTemplate(img,template,cv2.TM_CCOEFF)\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "cv2.rectangle(img,top_left, bottom_right, 255, 2)\n",
    "\n",
    "top_left_original = top_left\n",
    "bottom_right_original = bottom_right\n",
    "\n",
    "while(1):\n",
    "    #img = cv2.cvtColor(old_frame,cv2.COLOR_BGR2GRAY)\n",
    "    img = old_frame\n",
    "    \n",
    "    img2 = img.copy()\n",
    "    w, h ,l= template.shape[::-1]\n",
    "    # All the 6 methods for comparison in a list\n",
    "    #methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "    #            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "\n",
    "    #img = img2.copy()\n",
    "    # Apply template Matching\n",
    "    res = cv2.matchTemplate(img,template,cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(img,top_left, bottom_right, 255, 2)\n",
    "\n",
    "    \n",
    "    #transformacion para estabilizacion\n",
    "    tx1 = top_left_original[0]-top_left[0]\n",
    "    ty1 = top_left_original[1]-top_left[1]\n",
    "    tx2 = bottom_right_original[0]-bottom_right[0]\n",
    "    ty2 = bottom_right_original[1]-bottom_right[1]\n",
    "    \n",
    "    tx = (tx1+tx2)//2\n",
    "    ty = (ty1+ty2)//2\n",
    "\n",
    "    num_rows, num_cols = img.shape[:2]\n",
    "\n",
    "    translation_matrix = np.float32([ [1,0,tx], [0,1,ty] ])\n",
    "    img_translation = cv2.warpAffine(img2, translation_matrix, (num_cols, num_rows))\n",
    "    \n",
    "    img_translation=cv2.resize(img_translation,(width,height))\n",
    "    \n",
    "    salida.write(img_translation)\n",
    "    \n",
    "    cv2.imshow('Matching Result',res)\n",
    "    cv2.imshow('Detected Point',img)\n",
    "    cv2.imshow('Estabilizada',img_translation)\n",
    "    k = cv2.waitKey(10) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    ret, old_frame = cap.read()\n",
    "    if ret==0:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "salida.release()\n",
    "cap.release()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quita los obtaculos de la imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando la suma de todo lo que esta afuera de los rectangulos y creando una matris para saber cuantas veces se sumo cada pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\diego\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\diego\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:88: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\diego\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "# Read the video.\n",
    "#video = cv2.VideoCapture('video.avi')\n",
    "video = cv2.VideoCapture('video.avi')\n",
    "\n",
    "cantidadFrames=round(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "success,img = video.read()\n",
    "\n",
    "#BackgroundSubtractor\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "######\n",
    "\n",
    "\n",
    "aux=np.zeros(img.shape[:],dtype=\"uint64\")#inicia el auxiliar en con los valores en 0\n",
    "\n",
    "matrizContador=np.zeros(img.shape[:2],dtype=\"uint64\")#matriz para contar cuantas veces se sumo cada pixel\n",
    "maskAuxContador=np.zeros(img.shape[:2],dtype=\"uint8\")#mascara de cada imagen\n",
    "maskAuxContador[:,:]=1 #coloca la mascara del contador a 1\n",
    "\n",
    "with tf.gfile.FastGFile('frozen_inference_graph.pb','rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    # Restore session\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "        \n",
    "    for frame in range(1,cantidadFrames): \n",
    "            \n",
    "        success,img = video.read()\n",
    "        if success==0:#controla que queden frames\n",
    "            break\n",
    "        \n",
    "        \n",
    "        fgmask = fgbg.apply(img)\n",
    "        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "        mascara = cv2.bitwise_not(fgmask)    \n",
    "        \n",
    "        maskAuxContador[:,:]=1 #vuelve la mascara a blanco\n",
    "        rows = img.shape[0]\n",
    "        cols = img.shape[1]\n",
    "        inp = cv2.resize(img, (300, 300))\n",
    "        inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n",
    "\n",
    "        # Run the model\n",
    "        out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n",
    "                        sess.graph.get_tensor_by_name('detection_scores:0'),\n",
    "                        sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
    "                        sess.graph.get_tensor_by_name('detection_classes:0')],\n",
    "                       feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n",
    "\n",
    "        # Visualize detected bounding boxes.\n",
    "        num_detections = int(out[0][0])\n",
    "        for i in range(num_detections):\n",
    "            classId = int(out[3][0][i])\n",
    "            score = float(out[1][0][i])\n",
    "            bbox = [float(v) for v in out[2][0][i]]\n",
    "            if score > 0.3:\n",
    "                x = bbox[1] * cols\n",
    "                y = bbox[0] * rows\n",
    "                right = bbox[3] * cols\n",
    "                bottom = bbox[2] * rows\n",
    "                \n",
    "                #crea mascara para la suma\n",
    "                cv2.rectangle(img, (int(x), int(y)), (int(right), int(bottom)), (0, 0, 0), thickness=-1)\n",
    "                cv2.rectangle(maskAuxContador, (int(x), int(y)), (int(right), int(bottom)), (0, 0, 0), thickness=-1)\n",
    "    \n",
    "        matrizceros=np.zeros(img.shape[:],dtype=\"uint8\")\n",
    "        matrizcerosCont=np.zeros(maskAuxContador.shape[:],dtype=\"uint8\")\n",
    "        \n",
    "        img = cv2.add(img,matrizceros,mask=mascara)#enmascara la imagen dejando solamente el fondo\n",
    "        maskAuxContador = cv2.add(maskAuxContador,matrizcerosCont,mask=mascara)\n",
    "    \n",
    "        aux=aux+np.uint64(img)#suma la imagen auxiliar con la nueva imagen enmascarada\n",
    "        matrizContador=matrizContador+np.uint64(maskAuxContador)#suma a la matriz contador 1 menos en los pixeles enmascarados\n",
    "\n",
    "        #para previsualizar la imagen\n",
    "        \n",
    "        aux2=np.zeros(img.shape[:],dtype=\"uint64\")\n",
    "        aux2[:,:,0] = np.divide(aux[:,:,0],matrizContador)\n",
    "        aux2[:,:,1] = np.divide(aux[:,:,1],matrizContador)\n",
    "        aux2[:,:,2] = np.divide(aux[:,:,2],matrizContador)\n",
    "        \n",
    "        ##############################\n",
    "\n",
    "        cv2.imshow('TensorFlow MobileNet-SSD', np.uint8(aux2))\n",
    "        cv2.imshow('Actual', cv2.putText(img,str(frame), (40,40), cv2.FONT_HERSHEY_SIMPLEX, 2, 255))\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27:\n",
    "            break        \n",
    "            \n",
    "\n",
    "        \n",
    "cv2.imwrite(\"resultado.jpg\", np.uint8(aux2))\n",
    "cv2.imshow('Resultado', np.uint8(aux2))\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
